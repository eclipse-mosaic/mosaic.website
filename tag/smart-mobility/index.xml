<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>smart mobility | Eclipse MOSAIC â€“ A Multi-Domain and Multi-Scale Simulation Framework for Connected and Automated Mobility</title>
    <link>https://www.eclipse.dev/mosaic/tag/smart-mobility/</link>
      <atom:link href="https://www.eclipse.dev/mosaic/tag/smart-mobility/index.xml" rel="self" type="application/rss+xml" />
    <description>smart mobility</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 02 Jul 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://www.eclipse.dev/mosaic/images/logo.svg</url>
      <title>smart mobility</title>
      <link>https://www.eclipse.dev/mosaic/tag/smart-mobility/</link>
    </image>
    
    <item>
      <title>AI-NET-ANTILLAS - Perception for Remote Operated Driving</title>
      <link>https://www.eclipse.dev/mosaic/post/perception-remote-operated-driving/</link>
      <pubDate>Tue, 02 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://www.eclipse.dev/mosaic/post/perception-remote-operated-driving/</guid>
      <description>&lt;p&gt;&lt;strong&gt;After four years of research, the AI-NET-ANTILLAS project has concluded, and the final event took place in conjunction with the Berlin 6G Conference 2024. Collaborating with our partners,
we integrated several key components: Cloud-based LIDAR processing, next generation networks, and artificial intelligence,
to create a new service and application platform.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At DCAITI and Fraunhofer FOKUS, we concentrated on a specific use case: Remote Operated Driving.
For remote operators, it is essential to have a current and detailed understanding of the automated
vehicle&amp;rsquo;s surroundings. Processing the LIDAR data in the cloud enables the possibility of merging data from neighboring sensor sources to obtain a holistic picture and improve environment perception.
However, this application exhibits challenges in terms of latency, jitter, data volume, and scalability. These aspects have been studied thoroughly within the project.















&lt;figure id=&#34;figure-remote-operated-driving-with-data-from-two-sources&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./RemoteOperation.svg&#34; data-caption=&#34;Remote operated driving with data from two sources.&#34;&gt;


  &lt;img src=&#34;./RemoteOperation.svg&#34; alt=&#34;&#34; width=&#34;60%&#34; &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Remote operated driving with data from two sources.
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;cool-fusor&#34;&gt;COOL-Fusor&lt;/h2&gt;
&lt;p&gt;As a core component, we developed the &amp;ldquo;&lt;strong&gt;C&lt;/strong&gt;loud-based &lt;strong&gt;O&lt;/strong&gt;bject &lt;strong&gt;O&lt;/strong&gt;r &lt;strong&gt;L&lt;/strong&gt;idar (COOL)-Fusor&amp;rdquo; to merge data from multiple sensors in the same area, enhancing situational awareness.
The COOL-Fusor improves detection quality, particularly when one sensor is obstructed.
It operates on a server and ingests data from vehicles&#39; LIDAR sensors, communicated over the cellular network.
After the fusion step, object detection is performed on the combined data.&lt;/p&gt;















&lt;figure id=&#34;figure-scenario-with-cool-fusor-use-case&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./COOL_Fusor.png&#34; data-caption=&#34;Scenario with COOL Fusor use case.&#34;&gt;


  &lt;img src=&#34;./COOL_Fusor.png&#34; alt=&#34;&#34; width=&#34;100%&#34; &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Scenario with COOL Fusor use case.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;simulation&#34;&gt;Simulation&lt;/h2&gt;
&lt;p&gt;Our solution based on artificial intelligence for object detection required realistic sensor data on a large scale for training, testing and evaluation.
We leveraged Eclipse MOSAIC with its modelling capabilities and PHABMACS, our in-house vehicle simulator, accordingly.&lt;/p&gt;
&lt;p&gt;The simulated data for training our machine learning model included specific features of merged LIDAR point clouds from multiple vehicles.
Without simulation, the process of capturing these data with multiple vehicles would have been a prohibitively expensive and time-consuming endeavor.
We created numerous scenarios that include various vehicle maneuvers and environments, enabling us to compile a vast dataset tailored to our use case.
Furthermore, a simulated environment allows to create training data for virtually every situation imaginable, increasing coverage of different road layouts, street sights, and anomalies.&lt;/p&gt;















&lt;figure id=&#34;figure-picture-of-ai-net-antillas-scenarios-with-different-aspects&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./scenarios.png&#34; data-caption=&#34;Picture of AI-NET-ANTILLAS scenarios with different aspects&#34;&gt;


  &lt;img src=&#34;./scenarios.png&#34; alt=&#34;&#34; width=&#34;100%&#34; &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Picture of AI-NET-ANTILLAS scenarios with different aspects
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;training&#34;&gt;Training&lt;/h2&gt;
&lt;p&gt;To detect vehicle objects in the transmitted sensor data, we employed a machine learning model on the basis of the OGM (occupancy grid map) approach for LIDAR data.
Initially, the model was trained using data generated from our various scenarios.
Furthermore, we created datasets containing errors such as measurement inaccuracies, LiDAR acquisition errors, and limiting factors of the network such as delays and jitter.
These obstructions introduced more variety into the training and prepared the model for cases where the received data is suboptimal.
Continuous evaluation and retraining ensured the model remained robust and accurate, even as new data and scenarios were introduced.















&lt;figure id=&#34;figure-example-frame-with-model-detections-and-ground-truth-and-influence-of-errors-on-pointclouds&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./training.png&#34; data-caption=&#34;Example frame with model detections and ground truth and influence of errors on pointclouds&#34;&gt;


  &lt;img src=&#34;./training.png&#34; alt=&#34;&#34; width=&#34;80%&#34; &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Example frame with model detections and ground truth and influence of errors on pointclouds
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;network-and-transmission&#34;&gt;Network and Transmission&lt;/h2&gt;
&lt;p&gt;We further simulated the transmission of sensor data from vehicles to a remote server,
where the COOL-Fusor and object detection could be executed and visualized for the operator.
The network simulation was achieved using the Cell Simulator embedded in Eclipse MOSAIC.
This aspect of the project ensured that data transmission latency and bandwidth constraints were realistically modeled, providing insights into the performance of the overall remote operated driving systems under various network conditions.&lt;/p&gt;
&lt;h2 id=&#34;final-results&#34;&gt;Final results&lt;/h2&gt;
&lt;p&gt;Our final outcomes included a well-trained model for detecting car-sized vehicles in LiDAR point clouds, based on data simulated by Eclipse MOSAIC, and a novel point cloud fusion approach using the COOL-Fusor.
These results demonstrate the feasibility and effectiveness of our approach, paving the way for future advancements in remote and teleoperated driving and autonomous vehicle technologies.&lt;/p&gt;
&lt;div style=&#34;text-align: center;margin-bottom: 10px&#34;&gt;
&lt;video controls style=&#34;width:60%;margin-bottom: 1px;margin-top:3px;text-align: center&#34;&gt;
  &lt;source src=&#34;https://media.dcaiti.tu-berlin.de/mosaic/ai-net-rod/AINET-ANTILLAS-FINAL.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;b&gt;Watch this demonstration to get an overview of the capabilities implemented in Eclipse MOSAIC&lt;/b&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Simulated Testing of Traffic State Estimation using Eclipse MOSAIC</title>
      <link>https://www.eclipse.dev/mosaic/post/traffic-state-estimation/</link>
      <pubDate>Thu, 14 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://www.eclipse.dev/mosaic/post/traffic-state-estimation/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Daily commutes can quickly turn into stressful affairs when overcrowded roads become congested and what would be a 20 minute ride becomes an hour of staring at the license plate of your fellow comrade-in-traffic.
Real-time Traffic State Estimation (TSE) aims to alleviate this strain by predicatively recognizing congested areas and offering alternative routing options. In a recent publication we established a framework for easy implementation and evaluation of novel TSE systems.&lt;/strong&gt;&lt;/p&gt;
&lt;div style=&#34;position: relative; text-align: center; margin-bottom: 0&#34;&gt;
    &lt;div onmouseover=&#34;this.style.boxShadow=&#39;0 0 25px #68145CFF&#39;; this.style.scale=1.05&#34; onmouseout=&#34;this.style.boxShadow=&#39;none&#39;; this.style.scale=1.0&#34; style=&#34;display: flex; margin-left: auto; margin-right: auto; justify-content: center; width: fit-content; text-align: center; cursor: pointer; border: 2px solid #68145c; border-radius: 10px; padding: 10px; background-color: rgba(241,241,241,0.9); transform-origin: left center 0; position: absolute; top: 42%; left: 50%; transform: translate(-50%, -50%)&#34;&gt;
        &lt;!-- GitHub Icon --&gt;
        &lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 16 16&#34; fill=&#34;currentColor&#34; style=&#34;width: 40px; height: 40px;&#34;&gt;
          &lt;path fill-rule=&#34;evenodd&#34; d=&#34;M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.20-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.20-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.20-.82 2.20-.82.44 1.10.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.20 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z&#34;/&gt;
        &lt;/svg&gt;
        &lt;!-- GitHub Link --&gt;
        &lt;a href=&#34;https://github.com/mosaic-addons/traffic-state-estimation&#34; target=&#34;_blank&#34; style=&#34;border: 2px; border-radius: 5px; margin: auto 5px auto 5px; text-decoration: none; color: #68145C; font-weight: bold;&#34;&gt;GitHub Repository&lt;/a&gt;
    &lt;/div&gt;
    &lt;img src=&#34;banner.png&#34; style=&#34;margin-top: 0; margin-bottom: 0&#34; alt=&#34;Banner displaying a visualization of TSE&#34;&gt;
&lt;/div&gt;
&lt;p&gt;Nowadays, people have become used to having access to real-time traffic information in the palm of their hands using their smartphones.
However, navigation applications like Google MapsÂ© rely on large amounts of user data and don&amp;rsquo;t publish the algorithms used to retrieve the traffic information.
In an effort to make the implementation and evaluation of such Traffic State Estimation (TSE) systems more accessible, we developed an application tool chain for Eclipse MOSAIC that enables
quick prototyping in a simulated environment. They applications have been designed to be easily extendable so that you can develop your own TSE methods and compare them against results from conventional soluation.
For this purpose, we published all generated code on GitHub under the EPL-License, allowing free usage, customization, and deployment.&lt;/p&gt;
&lt;div style=&#34;display: flex; font-weight: bold; font-size: 20px; margin-left: auto; margin-right: auto; justify-content: center; width: fit-content; padding: 5px 10px; border: 2px solid #68145c; border-radius: 10px;&#34;&gt;â–¶&amp;emsp;&lt;a href=&#34;https://github.com/mosaic-addons/traffic-state-estimation&#34;&gt;https://github.com/mosaic-addons/traffic-state-estimation&lt;/a&gt;&amp;emsp;â—€&lt;/div&gt;
&lt;h3 id=&#34;research&#34;&gt;Research&lt;/h3&gt;
&lt;p&gt;The developed framework laid the foundation for our paper at the 




&lt;a href=&#34;https://simutools.eai-conferences.org/2023/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;EAI SIMUtools 2023&lt;/a&gt; conference, which received the &lt;strong&gt;Best Paper Award&lt;/strong&gt;.
In the paper, we aimed at reviewing commonly used sensors for Traffic State Estimation in an urban environment.
All experiments were conducted on-top the traffic simulator Eclipse SUMO and the calibrated 




&lt;a href=&#34;https://github.com/mosaic-addons/best-scenario&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BeST Scenario&lt;/a&gt; with traffic in the city of Berlin.
We compared mean speed estimates from traditional induction loops with now broadly adapted Floating Car Data (FCD) retrieved from connected vehicles.&lt;/p&gt;
&lt;p&gt;Furthermore, we identified that different sensor technologies require different ways of aggregating measured samples.
When using conventional induction loops, the Time and Space Mean Speed are commonly used, which are built by calculating the arithmetic and harmonic mean of samples measured within a time interval.
For FCD-based methods, we identified metrics defined by Yoon et al.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, namely the Temporal and Spatial Mean Speeds.
By comparing these values on different road types, we concluded that on highway-like streets with continuous traffic flow all metrics function equivalently.
However, especially if roads are signalized, conventional induction loop methods fail to properly capture the ground truth.&lt;/p&gt;















&lt;figure id=&#34;figure-speed-estimates-on-different-road-segments-in-berlin-charlottenburg-where-v_gthspace01cm-represents-the-ground-truth-speed-retrieved-from-sumo-v_tmshspace01cm-and-v_smshspace01cm-are-the-time-and-space-mean-speed-retrieved-from-virtual-induction-loops-v_texttemporalhspace01cm-and-v_textspatialhspace01cm-are-the-temporal-and-spatial-mean-speed-calculated-using-received-fcd&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./plot_all_streets.png&#34; data-caption=&#34;Speed estimates on different road segments in Berlin Charlottenburg. Where $V_{GT}\hspace{0.1cm}$ represents the ground truth speed retrieved from SUMO. $V_{TMS}\hspace{0.1cm}$ and $V_{SMS}\hspace{0.1cm}$ are the time and space mean speed, retrieved from virtual induction loops. $V_{\text{temporal}}\hspace{0.1cm}$ and $V_{\text{spatial}}\hspace{0.1cm}$ are the temporal and spatial mean speed calculated using received FCD.&#34;&gt;


  &lt;img src=&#34;./plot_all_streets.png&#34; alt=&#34;&#34; width=&#34;100%&#34; &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Speed estimates on different road segments in Berlin Charlottenburg. Where $V_{GT}\hspace{0.1cm}$ represents the ground truth speed retrieved from SUMO. $V_{TMS}\hspace{0.1cm}$ and $V_{SMS}\hspace{0.1cm}$ are the time and space mean speed, retrieved from virtual induction loops. $V_{\text{temporal}}\hspace{0.1cm}$ and $V_{\text{spatial}}\hspace{0.1cm}$ are the temporal and spatial mean speed calculated using received FCD.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Additionally, as part of our research, we also looked into required market penetration rates that can be used to still deliver reliable TSE.
We managed to reproduce results cited in literature and concluded that depending on the road type, reliable TSE requires a market penetration rate of 5â€“10% for city traffic.&lt;/p&gt;
&lt;p&gt;More details can be found in the paper &amp;raquo;Spatio-Temporal Speed Metrics for Traffic State Estimation on Complex Urban Roads&amp;laquo;.&lt;/p&gt;
&lt;h3 id=&#34;system-design&#34;&gt;System Design&lt;/h3&gt;
&lt;p&gt;Below, a simplified system overview is depicted. Using MOSAICs Mapping, we can equip however many vehicles with the &lt;em&gt;FcdTransmitterApp&lt;/em&gt;, which
will cause them to periodically record their positions, speeds, headings in the form of Floating Car Data and transmit it to the &lt;em&gt;TseServerApp&lt;/em&gt;.
At the heart of the server application runs a &lt;em&gt;TseKernel&lt;/em&gt; which handles the reception of FCD, traversal detection, and supervision of processors.
The kernel has been designed in a way to be easily extensible with custom processors that can individually handle received FCD and implement your own TSE metrics.
Currently, results will be stored in an SQLite database.&lt;/p&gt;















&lt;figure id=&#34;figure-simplified-system-overview&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./fcd-system-overview.drawio.png&#34; data-caption=&#34;Simplified System Overview&#34;&gt;


  &lt;img src=&#34;./fcd-system-overview.drawio.png&#34; alt=&#34;&#34; width=&#34;50%&#34; &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Simplified System Overview
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;whats-next&#34;&gt;What&amp;rsquo;s next?&lt;/h3&gt;
&lt;p&gt;In our current investigations, we only regarded calibrated traffic without major obstructions to measure mean speeds throughout the day.
However, the detection of said obstructions is one of the core use cases for TSE, so we aim to introduce and evaluate these in the future.&lt;/p&gt;
&lt;p&gt;More importantly, we are also interested in providing reliable TSE with even smaller market penetration rates by improving the data quality.
We aim to achieve this by using data from vehicular perception sensors (cameras, lidar) to enrich the Floating Car Dataset.&lt;/p&gt;
&lt;div style=&#34;display: flex; font-weight: bold; font-size: 20px; margin-left: auto; margin-right: auto; justify-content: center; width: fit-content; padding: 5px 10px; border: 2px solid #68145c; border-radius: 10px;&#34;&gt;â–¶&amp;emsp;&lt;a href=&#34;https://github.com/mosaic-addons/traffic-state-estimation&#34;&gt;https://github.com/mosaic-addons/traffic-state-estimation&lt;/a&gt;&amp;emsp;â—€&lt;/div&gt;
&lt;hr&gt;
&lt;p&gt;This work is related to our research in the 




&lt;a href=&#34;https://bmdv.bund.de/SharedDocs/DE/Artikel/DG/AVF-projekte/kis-m.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;KIS&amp;rsquo;M Project&lt;/a&gt;.
&lt;a href=&#34;https://bmdv.bund.de/SharedDocs/DE/Artikel/DG/AVF-projekte/kis-m.html&#34;&gt;&lt;img src=&#34;./kis-m.png&#34; style=&#34;width:35%;padding-top:0px;margin-top:2px&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Yoon, J., Noble, B., Liu, M.: Surface street traffic estimation. In: Proceedings of the 5th international conference on Mobile systems, applications and services. pp.220â€“232 (2007) &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
  </channel>
</rss>
